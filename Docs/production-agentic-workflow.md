---
description: Production-Ready Agentic Software Engineering Workflow - Optimized for Quality â†’ Clarity â†’ Reliability â†’ Speed
globs: []
alwaysApply: true
---

# Production Agentic Workflow: Quality-First Engineering

## Optimization Priority

**Quality** â†’ **Clarity** â†’ **Reliability** â†’ **Speed**

This workflow prioritizes:
1. **Quality**: Excellent code that solves problems correctly and elegantly
2. **Clarity**: Code that is understandable, maintainable, and well-documented
3. **Reliability**: Code that works consistently and handles edge cases
4. **Speed**: Efficient execution (but never at the expense of the above)

## Core Principles

### 1. Quality Through Thought Frameworks

Every task begins with selecting the appropriate reasoning strategy:

**For Standard Tasks**: Chain-of-Thought (CoT)
```
Break problem â†’ Solve step-by-step â†’ Validate each step
```

**For Complex Problems**: Strategic CoT or Tree of Thoughts
```
Identify optimal strategy â†’ Apply systematically â†’ Verify alignment
```

**For Novel Challenges**: First Principles
```
Strip to fundamentals â†’ Rebuild from scratch â†’ Validate against core needs
```

**For Exploration**: ReAct Loop
```
Reason â†’ Act â†’ Observe â†’ Iterate until complete
```

### 2. Clarity Through Communication

**Before Every Action**:
```
THOUGHT PROCESS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Goal: [What we're trying to achieve]

Current Understanding:
  â€¢ What we know: [facts]
  â€¢ What we don't know: [gaps]
  â€¢ Assumptions: [list any]

Approach:
  1. [Step 1 - why this matters]
  2. [Step 2 - how it connects]
  3. [Step 3 - expected outcome]

Risks & Mitigations:
  â€¢ Risk: [potential issue] â†’ Mitigation: [how to handle]

Success Criteria:
  â€¢ [How we know it works]

Confidence: [0.0-1.0]

Proceed? [Y/N]
```

**After Every Significant Action**:
```
REFLECTION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
What was done: [description]

Quality assessment:
  âœ“ Works correctly: [Y/N]
  âœ“ Code is clear: [Y/N]
  âœ“ Edge cases handled: [Y/N]
  âœ“ Well documented: [Y/N]

What could be better: [improvements]

Ready to continue? [Y/N]
```

### 3. Reliability Through Iterative Refinement

**Pattern**:
```
Iteration Loop (max: 5 iterations per component):
  
  1. GENERATE
     â”œâ”€ Apply thought framework
     â”œâ”€ Create implementation
     â””â”€ Add documentation inline
     
  2. CRITIQUE
     â”œâ”€ Does it solve the problem correctly?
     â”œâ”€ Is the code clear and readable?
     â”œâ”€ Are edge cases handled?
     â”œâ”€ Is error handling comprehensive?
     â”œâ”€ Does it follow project patterns?
     â””â”€ Is it maintainable?
     
  3. REFINE
     â”œâ”€ Select ONE issue to improve
     â”œâ”€ Make targeted change
     â””â”€ Validate change works
     
  4. VERIFY
     â”œâ”€ Run relevant tests
     â”œâ”€ Check linting
     â”œâ”€ Validate types
     â””â”€ Decision: KEEP or REVERT
     
  5. ITERATE OR COMPLETE
     â”œâ”€ Quality threshold met? â†’ COMPLETE
     â”œâ”€ Improvements possible? â†’ CONTINUE
     â””â”€ Max iterations reached? â†’ REVIEW WITH HUMAN
```

### 4. Speed Through Smart Context Management

**Stratified Context Retrieval** (inspired by AutoCodeRover):

```
LAYER 1 - High-Level Scan:
  Input: Task description
  Load: Module structure, key classes
  Decide: Relevant areas identified? [Y/N]

LAYER 2 - Targeted Dive:
  Input: Layer 1 results + task
  Load: Specific class/function implementations
  Decide: Sufficient understanding? [Y/N]

LAYER 3 - Precision Focus:
  Input: All previous context
  Load: Exact modification points + dependencies
  Decide: Ready to implement? [Y/N]

Exit when: Sufficient context OR max layers (5)
```

## Complete Workflow Execution

### Phase 1: Understanding

```
ğŸ“– UNDERSTANDING PHASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Parse Request
   â€¢ Read user's request carefully
   â€¢ Identify explicit requirements
   â€¢ Note implicit expectations
   â€¢ List any ambiguities

2. Clarify Ambiguities
   â“ Questions for human:
   â€¢ [Question 1]
   â€¢ [Question 2]
   
   Wait for answers before proceeding

3. Restate Understanding
   "My understanding is:
    - Goal: [restate in own words]
    - Success looks like: [concrete definition]
    - Out of scope: [what we won't do]
    
    Is this correct? [Y/N]"

4. Select Thought Framework
   Based on task type:
   â€¢ Standard â†’ CoT
   â€¢ Complex â†’ SCoT or ToT
   â€¢ Novel â†’ First Principles
   â€¢ Exploratory â†’ ReAct
   
   Justification: [why this framework]

âœ“ Phase Complete when understanding confirmed
```

### Phase 2: Planning

```
ğŸ“‹ PLANNING PHASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Decompose Task
   High-level breakdown:
   â–¡ Task 1: [description]
     â”œâ”€ Complexity: [Low/Med/High]
     â”œâ”€ Dependencies: [none or list]
     â””â”€ Verification: [how to test]
   
   â–¡ Task 2: [description]
     â””â”€ [same structure]
   
   [Continue for all tasks]

2. Identify Context Needs
   Files to understand:
   â€¢ [file 1] - Why: [reason]
   â€¢ [file 2] - Why: [reason]
   
   Knowledge gaps:
   â€¢ [gap 1] - How to fill: [approach]

3. Define Success Criteria
   This task is complete when:
   â–¡ [Criterion 1] - measurable
   â–¡ [Criterion 2] - measurable
   â–¡ [Criterion 3] - measurable
   
   Quality gates:
   â–¡ Tests pass
   â–¡ Code reviewed
   â–¡ Documentation updated
   â–¡ No linting errors

4. Estimate Confidence
   Confidence in plan: [0.0-1.0]
   
   If < 0.7:
     Concerns: [list]
     Need: [what would increase confidence]

5. Human Approval Gate
   â¸ï¸ PLAN REVIEW REQUIRED
   
   Show complete plan to human
   Get approval before implementation
   
   Adjustments requested: [if any]

âœ“ Phase Complete when plan approved
```

### Phase 3: Context Gathering

```
ğŸ” CONTEXT GATHERING PHASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Using Stratified Search:

â”Œâ”€ STRATUM 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scope: High-level structure  â”‚
â”‚ Goal: Identify relevant areasâ”‚
â”‚                              â”‚
â”‚ Search for:                  â”‚
â”‚ â€¢ Classes matching [keywords]â”‚
â”‚ â€¢ Methods matching [keywords]â”‚
â”‚ â€¢ Files containing [concepts]â”‚
â”‚                              â”‚
â”‚ Results: [summary]           â”‚
â”‚ Sufficient? [Y/N]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

If N, continue:

â”Œâ”€ STRATUM 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scope: Implementation detailsâ”‚
â”‚ Input: Stratum 1 + task      â”‚
â”‚                              â”‚
â”‚ Retrieve:                    â”‚
â”‚ â€¢ Full method implementationsâ”‚
â”‚ â€¢ Class structures           â”‚
â”‚ â€¢ Dependencies               â”‚
â”‚                              â”‚
â”‚ Results: [summary]           â”‚
â”‚ Sufficient? [Y/N]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Continue until sufficient or max strata

Final Context Summary:
  Files loaded: [count]
  Key components: [list]
  Dependencies: [list]
  Ready to implement: [Y/N]

âœ“ Phase Complete when context sufficient
```

### Phase 4: Implementation (Test-Driven)

```
ğŸ”¨ IMPLEMENTATION PHASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

For each task:

â”Œâ”€ RED: Write Test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              â”‚
â”‚ 1. Convert acceptance        â”‚
â”‚    criteria to test case     â”‚
â”‚                              â”‚
â”‚ 2. Implement test:           â”‚
â”‚    â€¢ Arrange (setup)         â”‚
â”‚    â€¢ Act (execute)           â”‚
â”‚    â€¢ Assert (verify)         â”‚
â”‚                              â”‚
â”‚ 3. Run test (expect FAIL)    â”‚
â”‚                              â”‚
â”‚ 4. Verify failure reason     â”‚
â”‚    correct                   â”‚
â”‚                              â”‚
â”‚ âœ“ Test fails for right reasonâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ GREEN: Make Test Pass â”€â”€â”€â”€â”€â”€â”
â”‚                              â”‚
â”‚ 1. Apply thought framework   â”‚
â”‚    to design solution        â”‚
â”‚                              â”‚
â”‚ 2. Implement MINIMAL code    â”‚
â”‚    to pass test              â”‚
â”‚                              â”‚
â”‚ 3. Add inline documentation  â”‚
â”‚    explaining approach       â”‚
â”‚                              â”‚
â”‚ 4. Run test (expect PASS)    â”‚
â”‚                              â”‚
â”‚ âœ“ Test passes                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ REFACTOR: Improve Quality â”€â”€â”
â”‚                              â”‚
â”‚ Iterative Refinement:        â”‚
â”‚                              â”‚
â”‚ Iteration 1:                 â”‚
â”‚   â€¢ Critique: [issue found]  â”‚
â”‚   â€¢ Refine: [improvement]    â”‚
â”‚   â€¢ Verify: Tests still pass â”‚
â”‚                              â”‚
â”‚ Iteration 2:                 â”‚
â”‚   â€¢ Critique: [issue found]  â”‚
â”‚   â€¢ Refine: [improvement]    â”‚
â”‚   â€¢ Verify: Tests still pass â”‚
â”‚                              â”‚
â”‚ [Continue until excellent]   â”‚
â”‚                              â”‚
â”‚ Final check:                 â”‚
â”‚ âœ“ Code is clear              â”‚
â”‚ âœ“ Well documented            â”‚
â”‚ âœ“ Handles edge cases         â”‚
â”‚ âœ“ Error handling complete    â”‚
â”‚ âœ“ Follows patterns           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Repeat for each task

âœ“ Phase Complete when all tasks implemented
```

### Phase 5: Verification

```
âœ… VERIFICATION PHASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Comprehensive Validation:

1. Test Suite
   â–¡ Run full test suite
   â–¡ All tests pass?
   
   If N:
     â€¢ Analyze failures
     â€¢ Fix issues
     â€¢ Retest
     â€¢ Repeat until all pass

2. Code Quality
   â–¡ Linting: [result]
   â–¡ Type checking: [result]
   â–¡ Complexity metrics: [acceptable?]
   â–¡ Code coverage: [percentage]
   
   If issues:
     â€¢ List problems
     â€¢ Fix each
     â€¢ Re-verify

3. Documentation
   â–¡ All functions documented?
   â–¡ Complex logic explained?
   â–¡ Examples provided?
   â–¡ README updated?

4. Edge Cases
   Review implementation:
   â€¢ What could go wrong? [list]
   â€¢ How is each handled? [verify]
   â€¢ Additional tests needed? [add]

5. Integration Check
   â–¡ Integrates with existing code?
   â–¡ No breaking changes?
   â–¡ Dependencies satisfied?
   â–¡ API contracts maintained?

6. Human Review Gate
   â¸ï¸ VERIFICATION REVIEW
   
   Show results to human:
   â€¢ What was implemented
   â€¢ Test results
   â€¢ Quality metrics
   â€¢ Files changed
   
   Approval: [Y/N]

âœ“ Phase Complete when all checks pass
```

### Phase 6: Reflection & Documentation

```
ğŸ“ REFLECTION PHASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Implementation Summary
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ WHAT WAS BUILT             â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Feature: [name]            â”‚
   â”‚ Files modified: [count]    â”‚
   â”‚ Tests added: [count]       â”‚
   â”‚ Lines changed: [estimate]  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Approach Reflection
   Strategy used: [framework]
   
   What went well:
   â€¢ [Success 1]
   â€¢ [Success 2]
   
   What was challenging:
   â€¢ [Challenge 1] - How solved: [approach]
   â€¢ [Challenge 2] - How solved: [approach]
   
   Learnings:
   â€¢ [Lesson 1]
   â€¢ [Lesson 2]

3. Quality Self-Assessment
   Quality (1-10): [score]
   Clarity (1-10): [score]
   Reliability (1-10): [score]
   
   Justification: [reasoning]

4. Improvement Opportunities
   Optional enhancements identified:
   
   1. [Enhancement 1]
      Impact: [High/Med/Low]
      Effort: [estimate]
      Justification: [why valuable]
   
   2. [Enhancement 2]
      [same structure]
   
   Pursue these? [Y/N/Select]

5. Documentation Update
   â–¡ Inline comments clear?
   â–¡ Function docstrings complete?
   â–¡ README reflects changes?
   â–¡ Architecture docs updated?
   â–¡ Examples added/updated?

âœ“ Phase Complete when documented
```

## Human-in-the-Loop Integration

### Mandatory Approval Gates

```
Gate 1: AFTER PLANNING
â”œâ”€ Show: Complete task breakdown
â”œâ”€ Show: Approach and thought framework
â”œâ”€ Show: Success criteria
â””â”€ Wait: Human approval

Gate 2: BEFORE MAJOR CHANGES
â”œâ”€ Show: Files to be modified
â”œâ”€ Show: Scope of changes
â”œâ”€ Show: Potential risks
â””â”€ Wait: Human approval

Gate 3: AFTER TEST FAILURES  
â”œâ”€ Show: Failed tests
â”œâ”€ Show: Root cause analysis
â”œâ”€ Show: Proposed fix
â””â”€ Wait: Human decision

Gate 4: BEFORE COMMIT
â”œâ”€ Show: All changes summary
â”œâ”€ Show: Test results
â”œâ”€ Show: Quality metrics
â””â”€ Wait: Final approval
```

### Progress Updates

Every 3-5 operations:
```
ğŸ“Š PROGRESS UPDATE [N/M complete]

Current: [what I'm doing now]
Last completed: [previous task]
Next: [upcoming task]

Status:
  âœ“ Going well: [aspect]
  âš ï¸ Concern: [if any]

Confidence: [0.0-1.0]
```

## Error Handling & Recovery

```
When error encountered:

1. STOP immediately
2. Classify error:
   â€¢ Syntax â†’ Parse error
   â€¢ Logic â†’ Wrong implementation
   â€¢ Test â†’ Failure in verification
   â€¢ Environment â†’ Missing dependency
   â€¢ Unknown â†’ Need investigation

3. Analyze:
   Error: [description]
   Context: [what was being done]
   Cause: [root cause analysis]

4. Propose recovery:
   Option A: [approach 1]
   Option B: [approach 2]
   Recommended: [which and why]

5. Human decision:
   â¸ï¸ ERROR RECOVERY DECISION NEEDED
   
   Present analysis and options
   Wait for human choice

6. Execute recovery:
   Follow human guidance
   Verify recovery successful
   Document what was learned
```

## Quality Standards

### Code Must Have

```
âœ“ Clear Function Names
  - Verb-based for actions
  - Descriptive of purpose
  - Follows project conventions

âœ“ Comprehensive Docstrings
  """
  Brief description of purpose.
  
  Args:
      param1 (type): Description
      param2 (type): Description
  
  Returns:
      type: Description
  
  Raises:
      ErrorType: When this occurs
  
  Example:
      >>> example_usage()
      expected_output
  """

âœ“ Inline Comments
  - Explain WHY, not WHAT
  - Complex logic explained
  - Edge case handling noted

âœ“ Error Handling
  - Input validation
  - Try-except blocks
  - Meaningful error messages
  - Graceful degradation

âœ“ Type Annotations
  def function(param: str) -> Dict[str, Any]:
      ...

âœ“ Tests
  - Unit tests for all functions
  - Edge cases covered
  - Error cases tested
  - Integration tests for endpoints
```

### Code Must Not Have

```
âœ— Magic numbers
  Use: MAX_RETRIES = 3
  Not: for i in range(3):

âœ— Unclear variable names
  Use: user_authentication_token
  Not: uat or x

âœ— Missing error handling
  Use: try-except with specific errors
  Not: bare except or none at all

âœ— Undocumented assumptions
  Document: "Assumes input is sorted"

âœ— Copy-paste duplication
  Extract: Shared logic to function

âœ— TODO without tracking
  Use: TODO(#123): Description
  Not: TODO: fix this later
```

## Workflow Optimization for Quality

### Favor Quality Over Speed

**When tempted to rush**:
```
STOP and ask:
  â€¢ Is this code clear enough?
  â€¢ Are edge cases handled?
  â€¢ Is it well tested?
  â€¢ Will my future self understand this?
  
If N to any: REFINE before continuing
```

**Quality Checklist** (before moving on):
```
â–¡ Code does what it should
â–¡ Code is easy to understand
â–¡ Edge cases are handled  
â–¡ Error handling is complete
â–¡ Tests are comprehensive
â–¡ Documentation is clear
â–¡ Patterns are followed
â–¡ No technical debt added
```

### Maximize Clarity

**Clarity Principles**:
```
1. Explicit > Implicit
   Prefer: clear_variable_name
   Over: short_name
   
2. Simple > Clever
   Prefer: readable_code
   Over: one_liner_magic
   
3. Documented > Self-Explanatory
   Even "obvious" code benefits from:
   - Purpose explanation
   - Context provision
   - Edge case notes
```

### Ensure Reliability

**Reliability Checklist**:
```
â–¡ Works with normal inputs
â–¡ Works with edge cases:
  â€¢ Empty inputs
  â€¢ Null/None values
  â€¢ Maximum values
  â€¢ Minimum values
  â€¢ Invalid types
â–¡ Handles errors gracefully
â–¡ Degrades gracefully under load
â–¡ Thread-safe (if concurrent)
â–¡ Resource cleanup handled
```

## Complete Example Execution

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TASK: Add Redis caching to user profile API
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”€â”€â”€ UNDERSTANDING â”€â”€â”€
Goal: Reduce database load by caching user profiles
Success: Response time < 100ms for cached requests
Framework: Strategic CoT (optimization problem)
âœ“ Understanding confirmed

â”€â”€â”€ PLANNING â”€â”€â”€
Tasks:
  1. Design cache key strategy
  2. Implement cache wrapper
  3. Add cache invalidation
  4. Write tests
  5. Update documentation

Context needs: user_profile.py, cache.py
âœ“ Plan approved

â”€â”€â”€ CONTEXT GATHERING â”€â”€â”€
Stratum 1: Located UserProfile class
Stratum 2: Retrieved get_profile() implementation
Stratum 3: Found existing cache utilities
âœ“ Context sufficient

â”€â”€â”€ IMPLEMENTATION â”€â”€â”€

Task 1: Design cache key strategy
  RED: Test cache key generation
  GREEN: Implement hash-based keys
  REFACTOR: Add documentation
  âœ“ Complete

Task 2: Implement cache wrapper
  RED: Test caching behavior
  GREEN: Add cache decorator
  REFACTOR: 
    - Iteration 1: Improve error handling
    - Iteration 2: Add logging
  âœ“ Complete

[Continue for remaining tasks]

â”€â”€â”€ VERIFICATION â”€â”€â”€
âœ“ All tests pass (25/25)
âœ“ Linting clean
âœ“ Type checking passed
âœ“ Coverage: 92%
âœ“ Documentation updated
âœ“ Human approved

â”€â”€â”€ REFLECTION â”€â”€â”€
Implementation successful
Quality: 9/10 - Well tested and documented
Clarity: 8/10 - Some complex logic explained
Reliability: 9/10 - Error cases handled

Learnings:
  â€¢ Cache invalidation is tricky
  â€¢ TTL-based approach works well

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TASK COMPLETE âœ“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

**Remember**: We optimize for Quality â†’ Clarity â†’ Reliability â†’ Speed
Take the time to do it right. Future you (and your team) will thank you.
